{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "num_devices = jax.device_count()\n",
    "device_type = jax.devices()[0].device_kind\n",
    "\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "print(f\"Found {num_devices} JAX devices of type {device_type}.\")\n",
    "# assert \"TPU\" in device_type, \"Available device is not a TPU, please select TPU from Edit > Notebook settings > Hardware accelerator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from pathlib import Path\n",
    "from jax import pmap\n",
    "from flax.jax_utils import replicate\n",
    "from flax.training.common_utils import shard\n",
    "from PIL import Image\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "from diffusers import FlaxStableDiffusionPipeline\n",
    "from diffusers import EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(\n",
    "#     \"runwayml/stable-diffusion-v1-5\",\n",
    "#     # revision=\"fp16\",\n",
    "#     dtype=jnp.float16,\n",
    "#     from_pt=True,\n",
    "# )\n",
    "\n",
    "pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    revision=\"bf16\",\n",
    "    dtype=jnp.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [2 ** x for x in range(0, 8)]\n",
    "steps = 50\n",
    "cfg_scale = 15.0\n",
    "prompt = \"postapocalyptic steampunk city, exploration, cinematic, realistic, hyper detailed, photorealistic maximum detail, volumetric light, (((focus))), wide-angle, (((brightly lit))), (((vegetation))), lightning, vines, destruction, devastation, wartorn, ruins\"\n",
    "negative_prompt = \"(((blurry))), ((foggy)), (((dark))), ((monochrome)), sun, (((depth of field)))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key(seed=0):\n",
    "    return jax.random.PRNGKey(seed)\n",
    "\n",
    "rng = create_key(0)\n",
    "rng = jax.random.split(rng, jax.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_warm\n",
    "batch_size = 1\n",
    "_prompt = [prompt] * batch_size\n",
    "prompt_ids = pipeline.prepare_inputs(_prompt)\n",
    "\n",
    "_neg_prompt = [negative_prompt] * batch_size\n",
    "neg_prompt_ids = pipeline.prepare_inputs(_neg_prompt)\n",
    "\n",
    "p_params = replicate(params)\n",
    "prompt_ids = shard(prompt_ids)\n",
    "\n",
    "neg_prompt_ids = shard(neg_prompt_ids)\n",
    "\n",
    "images = pipeline(\n",
    "    prompt_ids=prompt_ids,\n",
    "    neg_prompt_ids=neg_prompt_ids,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=cfg_scale,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    jit=True,\n",
    "    params=p_params,\n",
    "    prng_seed=rng,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    w,h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape((images.shape[0],) + images.shape[-3:])\n",
    "images = pipeline.numpy_to_pil(images)\n",
    "image_grid(images, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "batch_size_list = [1,1,2,2,4,4,8,8]\n",
    "for batch_size in batch_size_list:\n",
    "    try:\n",
    "        rng = jax.random.PRNGKey(0)\n",
    "        rng = jax.random.split(rng, num_devices)\n",
    "        \n",
    "        _prompt = [prompt] * batch_size\n",
    "        prompt_ids = pipeline.prepare_inputs(_prompt)\n",
    "\n",
    "        _neg_prompt = [negative_prompt] * batch_size\n",
    "        neg_prompt_ids = pipeline.prepare_inputs(_neg_prompt)\n",
    "\n",
    "        p_params = replicate(params)\n",
    "        prompt_ids = shard(prompt_ids)\n",
    "\n",
    "        neg_prompt_ids = shard(neg_prompt_ids)\n",
    "\n",
    "        # print(prompt_ids.shape)\n",
    "        # print(neg_prompt_ids.shape)\n",
    "\n",
    "        t0 = time.time()\n",
    "        images = pipeline(\n",
    "            prompt_ids=prompt_ids,\n",
    "            neg_prompt_ids=neg_prompt_ids,\n",
    "            num_inference_steps=50,\n",
    "            guidance_scale=cfg_scale,\n",
    "            height=512,\n",
    "            width=512,\n",
    "            jit=True,\n",
    "            params=p_params,\n",
    "            prng_seed=rng,\n",
    "        )[0]\n",
    "        t1 = time.time()\n",
    "        its = steps * batch_size / (t1 - t0)\n",
    "        print(\"batch_size {}, it/s: {}, time: {}\".format(batch_size, round(its, 2), round((t1 - t0), 2)))\n",
    "    except Exception:\n",
    "        print(traceback.print_exc())\n",
    "        print(\"batch_size {}, OOM\".format(batch_size))\n",
    "        its = 0\n",
    "    result.append(round(its, 2))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
